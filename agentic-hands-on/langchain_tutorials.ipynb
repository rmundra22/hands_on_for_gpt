{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3436d41-410f-495e-b9b7-f352e0d7b657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Using cached groq-1.0.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from groq) (4.0.0)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/jovyan/.local/lib/python3.11/site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/jovyan/.local/lib/python3.11/site-packages (from groq) (2.12.5)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /home/jovyan/.local/lib/python3.11/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->groq) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in /home/jovyan/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/jovyan/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/jovyan/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/jovyan/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/jovyan/.local/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
      "Using cached groq-1.0.0-py3-none-any.whl (138 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, groq\n",
      "Successfully installed distro-1.9.0 groq-1.0.0\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.2.1\n",
      "Collecting feedparser\n",
      "  Using cached feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting textblob\n",
      "  Using cached textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting sgmllib3k (from feedparser)\n",
      "  Using cached sgmllib3k-1.0.0-py3-none-any.whl\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Using cached nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk>=3.9->textblob) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk>=3.9->textblob) (1.3.2)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9->textblob)\n",
      "  Using cached regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from nltk>=3.9->textblob) (4.66.1)\n",
      "Using cached feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Using cached textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "Using cached nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached regex-2026.1.15-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)\n",
      "Installing collected packages: sgmllib3k, regex, feedparser, nltk, textblob\n",
      "Successfully installed feedparser-6.0.12 nltk-3.9.2 regex-2026.1.15 sgmllib3k-1.0.0 textblob-0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install groq\n",
    "!pip install python-dotenv\n",
    "!pip install feedparser textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9806301-d07e-4ac0-a4b5-8a2f710dc2a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# cwd = os.getcwd()\n",
    "# print(cwd)\n",
    "\n",
    "# os.chdir(\"/home/jovyan/fm-assist-volume/practice_gpt/hands_on_for_gpt/agentic-hands-on\") # Changes the current working directory\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b61981-6235-49c1-969e-b4218c83921f",
   "metadata": {},
   "source": [
    "# 1. Minimal Agent\n",
    "\n",
    "This is our simplest â€œagentâ€ using groq-api:\n",
    "\n",
    "* Has a role\n",
    "* Takes input\n",
    "* Produces reasoning-based output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8c418a-7a6e-438a-a519-9231ca113ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To explain Kafka vs API-based communication, let's break down each concept and compare them step by step.\n",
      "\n",
      "**API-based Communication:**\n",
      "\n",
      "1. **Definition:** API (Application Programming Interface) is a set of defined rules that enable different applications, systems, or services to communicate with each other.\n",
      "2. **Request-Response Model:** API-based communication follows a request-response model, where a client (e.g., a web application) sends a request to a server, and the server responds with the requested data.\n",
      "3. **Synchronous Communication:** API-based communication is typically synchronous, meaning that the client waits for the server's response before proceeding.\n",
      "4. **Point-to-Point Communication:** API-based communication is often point-to-point, meaning that a single client communicates with a single server.\n",
      "5. **Stateless:** API-based communication is typically stateless, meaning that each request contains all the necessary information to complete the request.\n",
      "\n",
      "**Kafka-based Communication:**\n",
      "\n",
      "1. **Definition:** Kafka is a distributed streaming platform that enables high-throughput, fault-tolerant, and scalable data processing.\n",
      "2. **Event-Driven Model:** Kafka-based communication follows an event-driven model, where producers (e.g., applications) publish events (e.g., messages) to a topic, and consumers (e.g., applications) subscribe to topics to receive events.\n",
      "3. **Asynchronous Communication:** Kafka-based communication is asynchronous, meaning that producers and consumers operate independently, and producers do not wait for consumers to respond.\n",
      "4. **Pub-Sub Model:** Kafka-based communication follows a pub-sub (publish-subscribe) model, where multiple producers can publish events to a topic, and multiple consumers can subscribe to the same topic.\n",
      "5. **Stateful:** Kafka-based communication can be stateful, meaning that Kafka maintains a state of the events published to a topic, allowing consumers to replay events if needed.\n",
      "\n",
      "**Comparison:**\n",
      "\n",
      "1. **Coupling:** API-based communication is tightly coupled, meaning that the client and server are closely connected. Kafka-based communication is loosely coupled, meaning that producers and consumers are decoupled, and changes to one do not affect the other.\n",
      "2. **Scalability:** Kafka-based communication is designed for high-throughput and scalability, making it suitable for large-scale, distributed systems. API-based communication can become bottlenecked as the number of requests increases.\n",
      "3. **Fault Tolerance:** Kafka-based communication provides fault tolerance through replication and redundancy, ensuring that events are not lost in case of failures. API-based communication relies on the server's availability and may not provide the same level of fault tolerance.\n",
      "4. **Complexity:** Kafka-based communication requires a more complex setup, including configuring Kafka clusters, topics, and consumer groups. API-based communication is often simpler to set up, with a focus on defining API endpoints and request-response models.\n",
      "\n",
      "**When to use each:**\n",
      "\n",
      "1. **API-based Communication:** Use for:\n",
      "\t* Simple, request-response interactions between applications.\n",
      "\t* Low-latency, synchronous communication.\n",
      "\t* Small-scale, centralized systems.\n",
      "2. **Kafka-based Communication:** Use for:\n",
      "\t* High-throughput, event-driven systems.\n",
      "\t* Large-scale, distributed systems.\n",
      "\t* Systems requiring fault tolerance, scalability, and loose coupling.\n",
      "\n",
      "In summary, API-based communication is suitable for simple, request-response interactions, while Kafka-based communication is designed for high-throughput, event-driven systems that require scalability, fault tolerance, and loose coupling.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "class SimpleAgent:\n",
    "    def __init__(self, system_prompt):\n",
    "        self.system_prompt = system_prompt\n",
    "\n",
    "    def run(self, user_input):\n",
    "        # use llm-client's chat completion service and models to generate a response\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            temperature=0.2\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "agent = SimpleAgent(\n",
    "    system_prompt=\"You are a helpful AI agent that reasons step by step.\"\n",
    ")\n",
    "\n",
    "print(agent.run(\"Explain Kafka vs API based communication\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae6c528-86ca-44a7-9e39-94e15f945980",
   "metadata": {},
   "source": [
    "# 2. Stateful Agent (Memory + Iterative Reasoning)\n",
    "\n",
    "Now this agent:\n",
    "\n",
    "* Remembers context\n",
    "* Builds conversation state\n",
    "* Can ask clarifying questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275c0a9-4a67-4c7c-819d-eb08dfc8d38c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Response from the llm:\n",
    "\n",
    "```\n",
    "ChatCompletion(\n",
    "    id='chatcmpl-c4554bf1-edd2-4c87-98c1-e4595aa5d831', \n",
    "    choices=[\n",
    "        Choice(\n",
    "            finish_reason='stop', \n",
    "            index=0, \n",
    "            logprobs=None, \n",
    "            message=ChatCompletionMessage(\n",
    "                content=\"To help you decide between Kafka and API, ... and I'll help you make an informed decision!\", \n",
    "                role='assistant', \n",
    "                annotations=None, \n",
    "                executed_tools=None, \n",
    "                function_call=None, \n",
    "                reasoning=None, \n",
    "                tool_calls=None\n",
    "            )\n",
    "        )\n",
    "    ], \n",
    "    created=1769932176, \n",
    "    model='llama-3.3-70b-versatile', \n",
    "    object='chat.completion', \n",
    "    mcp_list_tools=None, \n",
    "    service_tier='on_demand', \n",
    "    system_fingerprint='fp_43d97c5965', \n",
    "    usage=CompletionUsage(\n",
    "        completion_tokens=340, \n",
    "        prompt_tokens=56, \n",
    "        total_tokens=396, \n",
    "        completion_time=1.149168506, \n",
    "        completion_tokens_details=None, \n",
    "        prompt_time=0.002955258, \n",
    "        prompt_tokens_details=None, \n",
    "        queue_time=0.008930827, \n",
    "        total_time=1.152123764\n",
    "    ), \n",
    "    usage_breakdown=None, \n",
    "    x_groq=XGroq(\n",
    "        id='req_01kgc2ve1segyrev1pmj1b891k', \n",
    "        debug=None, \n",
    "        seed=831061670, \n",
    "        usage=None\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3420c08-453e-4a8c-a1ab-c2e06b5ea60b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To help you choose between Kafka and API, I need to understand your use case a bit better. Can you please provide some context about your project?\n",
      "\n",
      "Here are some clarifying questions to get started:\n",
      "\n",
      "1. What type of data are you trying to transfer or process? Is it real-time data, batch data, or a mix of both?\n",
      "2. What is the volume and velocity of the data? Are we talking about a small amount of data or a large-scale data pipeline?\n",
      "3. What are the producers and consumers of the data? Are they internal microservices, external services, or a combination of both?\n",
      "4. Do you need to handle events, messages, or requests? Are there any specific requirements for data ordering, deduplication, or guaranteed delivery?\n",
      "5. What are your scalability, reliability, and fault-tolerance requirements?\n",
      "6. Are there any specific technologies or frameworks you're already using or planning to use?\n",
      "\n",
      "Once I have a better understanding of your requirements, I can help you decide whether Kafka, API, or a combination of both is the best fit for your use case.\n",
      "\n",
      "Also, just to clarify, when you say \"API\", I assume you mean a traditional RESTful API or a similar request-response style API. Is that correct?\n",
      "With a downstream SLA (Service Level Agreement) of 4 hours, it means that the downstream system or consumer of the data has a requirement to receive the data within a 4-hour window.\n",
      "\n",
      "This information helps to inform the design decision between Kafka and API. Here are a few implications of this SLA:\n",
      "\n",
      "1. **Latency tolerance**: Since the downstream system has a 4-hour window to receive the data, it implies that there is some tolerance for latency in the system. This means that the system doesn't require real-time or near-real-time data processing.\n",
      "2. **Batching**: Given the 4-hour window, it's possible to batch data and process it in chunks, rather than processing each event or message individually. This could be beneficial for reducing the load on the system and improving efficiency.\n",
      "3. **Queueing**: With a 4-hour SLA, it's also possible to use a message queue or a similar mechanism to store data temporarily while it's being processed. This can help to decouple the producer and consumer systems and provide a buffer against any temporary issues or backlogs.\n",
      "\n",
      "Considering these implications, Kafka might be a good fit for this use case, as it's designed for handling high-throughput and provides low-latency, fault-tolerant, and scalable data processing. Kafka's ability to handle batched data and provide a buffer against backlogs could be beneficial in meeting the 4-hour SLA.\n",
      "\n",
      "However, I still have a few more questions to ensure that Kafka is the best choice:\n",
      "\n",
      "1. **Data size and complexity**: What is the average size of the data being processed, and how complex is the data structure?\n",
      "2. **Producer and consumer systems**: Can you describe the systems that will be producing and consuming the data? Are they internal microservices, external services, or a combination of both?\n",
      "3. **Data processing requirements**: Are there any specific data processing requirements, such as data transformation, aggregation, or filtering, that need to be performed on the data before it's sent to the downstream system?\n",
      "\n",
      "Once I have a better understanding of these factors, I can provide a more informed recommendation on whether Kafka or API (or a combination of both) is the best choice for your use case.\n",
      "agent workflow as chat: \n",
      "\n",
      "[{'content': 'You are a senior system design agent. Ask clarifying questions '\n",
      "             'when needed.',\n",
      "  'role': 'system'},\n",
      " {'content': 'Help me choose Kafka vs API', 'role': 'user'},\n",
      " {'content': 'To help you choose between Kafka and API, I need to understand '\n",
      "             'your use case a bit better. Can you please provide some context '\n",
      "             'about your project?\\n'\n",
      "             '\\n'\n",
      "             'Here are some clarifying questions to get started:\\n'\n",
      "             '\\n'\n",
      "             '1. What type of data are you trying to transfer or process? Is '\n",
      "             'it real-time data, batch data, or a mix of both?\\n'\n",
      "             '2. What is the volume and velocity of the data? Are we talking '\n",
      "             'about a small amount of data or a large-scale data pipeline?\\n'\n",
      "             '3. What are the producers and consumers of the data? Are they '\n",
      "             'internal microservices, external services, or a combination of '\n",
      "             'both?\\n'\n",
      "             '4. Do you need to handle events, messages, or requests? Are '\n",
      "             'there any specific requirements for data ordering, '\n",
      "             'deduplication, or guaranteed delivery?\\n'\n",
      "             '5. What are your scalability, reliability, and fault-tolerance '\n",
      "             'requirements?\\n'\n",
      "             \"6. Are there any specific technologies or frameworks you're \"\n",
      "             'already using or planning to use?\\n'\n",
      "             '\\n'\n",
      "             'Once I have a better understanding of your requirements, I can '\n",
      "             'help you decide whether Kafka, API, or a combination of both is '\n",
      "             'the best fit for your use case.\\n'\n",
      "             '\\n'\n",
      "             'Also, just to clarify, when you say \"API\", I assume you mean a '\n",
      "             'traditional RESTful API or a similar request-response style API. '\n",
      "             'Is that correct?',\n",
      "  'role': 'assistant'},\n",
      " {'content': 'Downstream SLA is 4 hours\\n', 'role': 'user'},\n",
      " {'content': 'With a downstream SLA (Service Level Agreement) of 4 hours, it '\n",
      "             'means that the downstream system or consumer of the data has a '\n",
      "             'requirement to receive the data within a 4-hour window.\\n'\n",
      "             '\\n'\n",
      "             'This information helps to inform the design decision between '\n",
      "             'Kafka and API. Here are a few implications of this SLA:\\n'\n",
      "             '\\n'\n",
      "             '1. **Latency tolerance**: Since the downstream system has a '\n",
      "             '4-hour window to receive the data, it implies that there is some '\n",
      "             'tolerance for latency in the system. This means that the system '\n",
      "             \"doesn't require real-time or near-real-time data processing.\\n\"\n",
      "             \"2. **Batching**: Given the 4-hour window, it's possible to batch \"\n",
      "             'data and process it in chunks, rather than processing each event '\n",
      "             'or message individually. This could be beneficial for reducing '\n",
      "             'the load on the system and improving efficiency.\\n'\n",
      "             \"3. **Queueing**: With a 4-hour SLA, it's also possible to use a \"\n",
      "             'message queue or a similar mechanism to store data temporarily '\n",
      "             \"while it's being processed. This can help to decouple the \"\n",
      "             'producer and consumer systems and provide a buffer against any '\n",
      "             'temporary issues or backlogs.\\n'\n",
      "             '\\n'\n",
      "             'Considering these implications, Kafka might be a good fit for '\n",
      "             \"this use case, as it's designed for handling high-throughput and \"\n",
      "             'provides low-latency, fault-tolerant, and scalable data '\n",
      "             \"processing. Kafka's ability to handle batched data and provide a \"\n",
      "             'buffer against backlogs could be beneficial in meeting the '\n",
      "             '4-hour SLA.\\n'\n",
      "             '\\n'\n",
      "             'However, I still have a few more questions to ensure that Kafka '\n",
      "             'is the best choice:\\n'\n",
      "             '\\n'\n",
      "             '1. **Data size and complexity**: What is the average size of the '\n",
      "             'data being processed, and how complex is the data structure?\\n'\n",
      "             '2. **Producer and consumer systems**: Can you describe the '\n",
      "             'systems that will be producing and consuming the data? Are they '\n",
      "             'internal microservices, external services, or a combination of '\n",
      "             'both?\\n'\n",
      "             '3. **Data processing requirements**: Are there any specific data '\n",
      "             'processing requirements, such as data transformation, '\n",
      "             'aggregation, or filtering, that need to be performed on the data '\n",
      "             \"before it's sent to the downstream system?\\n\"\n",
      "             '\\n'\n",
      "             'Once I have a better understanding of these factors, I can '\n",
      "             'provide a more informed recommendation on whether Kafka or API '\n",
      "             '(or a combination of both) is the best choice for your use case.',\n",
      "  'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from pprint import pprint\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "class MemoryAgent:\n",
    "    def __init__(self, system_prompt):\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    def run(self, user_input):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            messages=self.messages,\n",
    "            temperature=0.2\n",
    "        )\n",
    "\n",
    "        assistant_msg = response.choices[0].message.content\n",
    "        \n",
    "        # save the response into a memory building a new context\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        return assistant_msg\n",
    "\n",
    "\n",
    "agent = MemoryAgent(\n",
    "    system_prompt=\"You are a senior system design agent. Ask clarifying questions when needed.\"\n",
    ")\n",
    "\n",
    "print(agent.run(\"Help me choose Kafka vs API\"))\n",
    "print(agent.run(\"Downstream SLA is 4 hours\\n\"))\n",
    "print(f\"agent workflow as chat: \\n\")\n",
    "pprint(agent.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a22765-8835-4c84-b2e8-ccf334edcbe6",
   "metadata": {},
   "source": [
    "# 3. Tool-Calling Agent (True â€œAgenticâ€ Behavior)\n",
    "\n",
    "Agent decides whether to call a tool or think. We can then:\n",
    "\n",
    "* Parse structured JSON\n",
    "* Holds memory (messages)\n",
    "* Registers tools\n",
    "* Runs agent loop (Loop until task completes)\n",
    "* Executes tools\n",
    "* Returns final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87128d86-59e6-40a8-b632-ddc490e8456f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, model=\"llama-3.3-70b-versatile\"):\n",
    "        self.client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "        self.model = model\n",
    "\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are a senior system design agent.\\n\"\n",
    "                    \"- If information is missing, ask clarifying questions.\\n\"\n",
    "                    \"- If enough information is available, call the tool ONCE.\\n\"\n",
    "                    \"- After receiving tool output, provide a FINAL answer.\\n\"\n",
    "                    \"- Do NOT call tools again after a tool result.\"\n",
    "                ) # system_prompt given at the start\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # defining tool-schema clearly\n",
    "        self.tools = [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"choose_transport\",\n",
    "                    \"description\": \"Decide Kafka vs API based on system constraints\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"sla_hours\": {\"type\": \"integer\"},\n",
    "                            \"volume\": {\"type\": \"integer\"},\n",
    "                            \"push\": {\"type\": \"boolean\"}\n",
    "                        },\n",
    "                        \"required\": [\"sla_hours\", \"volume\", \"push\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        self.tool_used = False  # ðŸ”’ critical flag\n",
    "\n",
    "    # --------------------\n",
    "    # Tool implementation\n",
    "    # --------------------\n",
    "    def choose_transport(self, sla_hours: int, volume: int, push: bool) -> dict:\n",
    "        if push and sla_hours >= 2 and volume >= 1000:\n",
    "            return {\n",
    "                \"decision\": \"Kafka\",\n",
    "                \"reason\": \"High volume, async SLA, push-based architecture\"\n",
    "            }\n",
    "        return {\n",
    "            \"decision\": \"API\",\n",
    "            \"reason\": \"Lower volume or synchronous requirement\"\n",
    "        }\n",
    "\n",
    "    def _execute_tool(self, name: str, args: dict) -> dict:\n",
    "        if name == \"choose_transport\":\n",
    "            return self.choose_transport(**args)\n",
    "        raise ValueError(f\"Unknown tool: {name}\")\n",
    "\n",
    "    # --------------------\n",
    "    # Agent loop\n",
    "    # --------------------\n",
    "    def run(self, user_input: str, max_steps: int = 5) -> str:\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        \n",
    "        # run agent on-loop to assist a conversation\n",
    "        for step in range(max_steps):\n",
    "            # use llm-client's chat completion service and models to generate a response\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages,\n",
    "                # allowing tool usage at max once - this will ensure agent\n",
    "                # doesn't try infinite tool calls\n",
    "                tools=self.tools if not self.tool_used else None,\n",
    "                tool_choice=\"auto\" if not self.tool_used else \"none\",\n",
    "                temperature=0\n",
    "            )\n",
    "\n",
    "            message = response.choices[0].message\n",
    "\n",
    "            # ðŸ”§ Tool call (only once)\n",
    "            if message.tool_calls and not self.tool_used:\n",
    "                self.tool_used = True\n",
    "\n",
    "                tool_call = message.tool_calls[0]\n",
    "                tool_name = tool_call.function.name\n",
    "                tool_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "                print(f\"\\nðŸ”§ Tool called: {tool_name}({tool_args})\")\n",
    "\n",
    "                result = self._execute_tool(tool_name, tool_args)\n",
    "\n",
    "                self.messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(result)\n",
    "                })\n",
    "\n",
    "            # âœ… Final answer\n",
    "            else:\n",
    "                self.messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": message.content\n",
    "                })\n",
    "                return message.content\n",
    "\n",
    "        raise RuntimeError(\"Agent did not completed within max steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1fa44c2-f397-4db5-a408-f77a0b3197c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”§ Tool called: choose_transport({'push': True, 'sla_hours': 4, 'volume': 1000})\n",
      "\n",
      "âœ… FINAL OUTPUT:\n",
      " FINAL ANSWER: Based on the provided information, the recommended system design is Kafka. This is because Kafka is well-suited for handling high volumes of data, has an asynchronous SLA that can accommodate the 4-hour downstream SLA, and is designed for push-based architectures, making it a good fit for the described use case.\n"
     ]
    }
   ],
   "source": [
    "agent = ToolAgent()\n",
    "\n",
    "output = agent.run(\n",
    "    \"Push-based system, thousands of comparisons per run, \"\n",
    "    \"downstream SLA is 4 hours\"\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… FINAL OUTPUT:\\n\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad9dac-82c9-4ba0-a23e-ba10182c0de2",
   "metadata": {},
   "source": [
    "# $ Using Abstract Class to call multiple tools cleanly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dbeb1f-8f65-4186-9c73-8b27d552ba2e",
   "metadata": {},
   "source": [
    "## 1. Create a base class to define tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eae84d5-e49c-49ea-bda9-1c820b41a802",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BaseTool(ABC):\n",
    "    name: str\n",
    "    description: str\n",
    "\n",
    "    @abstractmethod\n",
    "    def schema(self) -> dict:\n",
    "        \"\"\"Return OpenAI/Groq-compatible tool schema\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def run(self, **kwargs) -> dict:\n",
    "        \"\"\"Execute tool\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b4b068-4032-49d8-a5f2-fabff828eee9",
   "metadata": {},
   "source": [
    "## 2. Create each tool using abstract class\n",
    "\n",
    "* Each tool should inherit and override base class functions\n",
    "* This abstract class ensures that all the functional tools are written with uniformity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320fcd7f-d634-4dcc-a404-522dde39def3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ChooseTransportTool(BaseTool):\n",
    "    name = \"choose_transport\"\n",
    "    description = \"Decide Kafka vs API based on system constraints\"\n",
    "\n",
    "    def schema(self) -> dict:\n",
    "        return {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": self.name,\n",
    "                \"description\": self.description,\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"sla_hours\": {\"type\": \"integer\"},\n",
    "                        \"volume\": {\"type\": \"integer\"},\n",
    "                        \"push\": {\"type\": \"boolean\"}\n",
    "                    },\n",
    "                    \"required\": [\"sla_hours\", \"volume\", \"push\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def run(self, sla_hours: int, volume: int, push: bool) -> dict:\n",
    "        if push and sla_hours >= 2 and volume >= 1000:\n",
    "            return {\"transport\": \"Kafka\"}\n",
    "        return {\"transport\": \"API\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106a4a2-cd26-4225-b070-248139bc90f1",
   "metadata": {},
   "source": [
    "## 3. Create a tool registry to call all the tools\n",
    "\n",
    "* Clean separation\n",
    "* Single source of truth\n",
    "* Easy extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fe61e55-7439-45ad-8f21-32955f6226b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToolRegistry:\n",
    "    def __init__(self, tools: list[BaseTool]):\n",
    "        self._tools = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def schemas(self) -> list[dict]:\n",
    "        \"\"\"Expose all tool schemas to LLM\"\"\"\n",
    "        return [tool.schema() for tool in self._tools.values()]\n",
    "\n",
    "    def execute(self, name: str, args: dict) -> dict:\n",
    "        if name not in self._tools:\n",
    "            raise ValueError(f\"Tool '{name}' not registered\")\n",
    "        return self._tools[name].run(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4f6f7-1060-42f6-b334-f46566c3ee19",
   "metadata": {},
   "source": [
    "## 4. Agent Using tool registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2f6375-77a6-4cde-bb7d-24250659b76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ToolAgent:\n",
    "    def __init__(self, tool_registry, client, model):\n",
    "        self.tool_registry = tool_registry\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.tool_used = False\n",
    "\n",
    "        self.messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": (\n",
    "                    \"You are an expert agent. \"\n",
    "                    \"Call at most one tool, then conclude.\"\n",
    "                )\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def run(self, user_input: str):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=self.messages,\n",
    "            tools=self.tool_registry.schemas(),\n",
    "            tool_choice=\"auto\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        msg = response.choices[0].message\n",
    "\n",
    "        if msg.tool_calls:\n",
    "            call = msg.tool_calls[0]\n",
    "            result = self.tool_registry.execute(\n",
    "                call.function.name,\n",
    "                json.loads(call.function.arguments)\n",
    "            )\n",
    "\n",
    "            self.messages.append({\n",
    "                \"role\": \"tool\",\n",
    "                \"tool_call_id\": call.id,\n",
    "                \"content\": json.dumps(result)\n",
    "            })\n",
    "\n",
    "            final = self.client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=self.messages,\n",
    "                temperature=0\n",
    "            )\n",
    "\n",
    "            return final.choices[0].message.content\n",
    "\n",
    "        return msg.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0911b591-e9b6-4923-af5d-588764b2a6a0",
   "metadata": {},
   "source": [
    "## 5. Run the agentic-frameowrk with multiple tools and memory\n",
    "\n",
    "Why this design scales\n",
    "\n",
    "* One abstract contract\n",
    "* Self-contained tools\n",
    "* Zero agent coupling\n",
    "* Easy testing (tool.run() standalone)\n",
    "* Auto-discoverable schemas\n",
    "* Production-ready\n",
    "\n",
    "> NOTE: This is exactly how internal agent platforms are structured (minus internal infra)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea141aa2-fb2c-401f-b714-9459bfb7ffcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information provided, it seems like you're describing a system that requires a high-volume data processing solution with a Service Level Agreement (SLA) of 4 hours. Given the push-based nature and the need to handle high volumes of data within a specific time frame, utilizing Apache Kafka as the transport mechanism is a suitable choice.\n",
      "\n",
      "Kafka is designed for high-throughput and provides low-latency, fault-tolerant, and scalable data processing. It's particularly useful in push-based systems where data is continuously being generated and needs to be processed in real-time or near real-time. Kafka's ability to handle high volumes of data and its reliability features make it a good fit for applications that have strict SLAs, such as the 4-hour window mentioned.\n",
      "\n",
      "Therefore, the conclusion is that using Kafka as the transport mechanism is an appropriate decision for this scenario, given its capabilities in handling high-volume data streams and supporting the required SLA.\n",
      "For a payment gateway system with a push-based architecture, high volume, and a Service Level Agreement (SLA) of 4 hours, a suitable design could involve the following components:\n",
      "\n",
      "1. **Load Balancer**: To distribute the incoming traffic across multiple servers, ensuring no single point of failure and efficient handling of high volumes.\n",
      "2. **Kafka Cluster**: As the messaging system, Kafka can handle high-throughput and provides low-latency, fault-tolerant, and scalable data processing. It's ideal for a push-based system where data is constantly being pushed from various sources.\n",
      "3. **Payment Processing Nodes**: These nodes would be responsible for processing payments. They would consume messages from Kafka topics, perform the necessary operations (e.g., payment validation, transaction processing), and then produce the outcome to another Kafka topic for further handling (e.g., notification, logging).\n",
      "4. **Database**: For storing payment records, user information, and other relevant data. The database should be designed for high availability and performance.\n",
      "5. **Notification Service**: To send notifications to users about the status of their payments (e.g., success, failure). This could be integrated with email services, SMS gateways, etc.\n",
      "\n",
      "As for PayPal's stock price, I'm an AI and do not have real-time access to current market data. However, I can suggest checking financial news websites such as Bloomberg, Yahoo Finance, or Google Finance for the most recent information on PayPal's stock price (PYPL). Please note that stock prices fluctuate constantly and are influenced by a wide range of factors, including company performance, market trends, and global economic conditions.\n",
      "\n",
      "For example, as of my last update in 2023, you could find PayPal's stock price and news by visiting these financial websites. Remember, the stock market is subject to rapid changes, so it's essential to consult current data for investment decisions or to stay informed about market trends.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from tools import *\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# create a list of tools that you want our agent to use\n",
    "tools = [\n",
    "    ChooseTransportTool(),\n",
    "    EstimateCostTool(),\n",
    "    EstimateLatencyTool(),\n",
    "    FetchNewsTool(),\n",
    "    PlotTopicFrequencyTool(),\n",
    "    AnalyzeSentimentTool(),\n",
    "    # Add more tools here\n",
    "]\n",
    "\n",
    "# register all the tools to ToolRegistry\n",
    "registry = ToolRegistry(tools)\n",
    "\n",
    "# call the tool integrated agent for response generation task\n",
    "agent = ToolAgent(\n",
    "    tool_registry=registry,\n",
    "    client=client,\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "print(agent.run(\"Push-based system, high volume, SLA 4 hours\"))\n",
    "print(agent.run(\"Give details for a payment gateway system and give me news on Paypal stock price with date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5ff6568-70fe-4589-8960-c7fb004c5854",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are an expert agent. Call at most one tool, then conclude.'},\n",
       " {'role': 'user', 'content': 'Push-based system, high volume, SLA 4 hours'},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'zqx478n84',\n",
       "  'content': '{\"transport\": \"Kafka\"}'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give details for a payment gateway system and give me news on Paypal stock price with date'},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'g4g9cksgd',\n",
       "  'content': '{\"transport\": \"Kafka\"}'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me news on Paypal stock price with date and plot graph for last 1 year stock price'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me news on Paypal stock price and plot graph for last 1 year stock price'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me headline related to Target and Plot most frequent words in headlines'},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': '8ver3995s',\n",
       "  'content': '{\"headlines\": [\"Target\\\\u2019s New C.E.O. Faces Hometown Crisis as He Begins Turnaround Effort - The New York Times\", \"Anti-ICE protesters call for national action against federal immigration tactics - NPR\", \"Demonstrators in Dinkytown call for Target to speak out against ICE - CBS News\", \"Target employees are stepping in where the company won\\'t, as an ICE crackdown grips Minneapolis - Business Insider\", \"Seven detained outside West Loop Target as protesters demand retailer stand against ICE - Chicago Tribune\", \"Nottingham Forest agree deal for Stefan Ortega and target Davide Frattesi - BBC\", \"Campus Radicals: Dems target military school, Chicago teachers wreak havoc, college nurse\\'s viral scandal - Fox News\", \"The Triangle\\\\u2019s newest Target store opens soon. Here\\\\u2019s when to go - News & Observer\", \"ICE eyeing Ohio next, where it is expected to target Haitian immigrants - MS NOW\", \"Target in Greece operating without running water - 13wham.com\"]}'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me headline related to Target, Plot most frequent words in headlines and Analyze sentiment of text headlines'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me headline related to Target, and Analyze sentiment of text headlines'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me headline related to Target and Analyze sentiment of text headlines'},\n",
       " {'role': 'user',\n",
       "  'content': 'Give me headline related to Target and Plot most frequent words in headlines'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed894781-7397-4176-a669-7ae265b8fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.run(\"Give me headline related to Target and Plot most frequent words in headlines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa9b8a9b-0ebb-4a33-ad13-50d413feb29f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "headlines = [\"Targetâ€™s New C.E.O. Faces Hometown Crisis as He Begins Turnaround Effort - The New York Times\", \"Anti-ICE protesters call for national action against federal immigration tactics - NPR\", \"Demonstrators in Dinkytown call for Target to speak out against ICE - CBS News\", \"Target employees are stepping in where the company won't, as an ICE crackdown grips Minneapolis - Business Insider\", \"Seven detained outside West Loop Target as protesters demand retailer stand against ICE - Chicago Tribune\", \"Nottingham Forest agree deal for Stefan Ortega and target Davide Frattesi - BBC\", \"Campus Radicals: Dems target military school, Chicago teachers wreak havoc, college nurse's viral scandal - Fox News\", \"The Triangleâ€™s newest Target store opens soon. Hereâ€™s when to go - News & Observer\", \"ICE eyeing Ohio next, where it is expected to target Haitian immigrants - MS NOW\", \"Target in Greece operating without running water - 13wham.com\"]\n",
    "\n",
    "words = []\n",
    "for headline in headlines:\n",
    "    words.extend(re.findall(r'\\b\\w+\\b', headline.lower()))\n",
    "\n",
    "word_freq = Counter(words)\n",
    "most_common_words = word_freq.most_common(10)\n",
    "\n",
    "words, freq = zip(*most_common_words)\n",
    "plt.bar(words, freq)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Most Frequent Words in Headlines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b99256eb-b033-49c5-a9be-53410d827246",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average sentiment of the text headlines is 0.009, indicating a slightly positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "print(agent.run(\"Give me Analyze sentiment of text headlines\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423caf55-fa95-4b82-b28f-396e5d39f6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
